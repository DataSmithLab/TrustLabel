{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Star\n",
    "# 2. Folk\n",
    "# 3. Watching\n",
    "# 4. Commits\n",
    "# 5. Issue\n",
    "# 6. PL \n",
    "# 7. Pull Request\n",
    "# 8. Actions \n",
    "# 9. Docs \n",
    "# 10. Contributor\n",
    "# 11. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06b71672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timezone\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada30918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the metrics calculated will be saved in '../metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b718146",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data_path = \"/Users/zhangyujin/Desktop/repos-data\"\n",
    "metrics_path = \"../metrics.csv\"\n",
    "metrics = pd.read_csv(metrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 repo_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d715f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['stars'] = None\n",
    "metrics['forks'] = None\n",
    "metrics['watchers'] = None\n",
    "metrics['open_issues'] = None\n",
    "metrics['network_count'] = None\n",
    "metrics['subscribers_count'] = None\n",
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    repo_path = f\"{repos_data_path}/{owner}_{repo}\"\n",
    "    if os.path.exists(repo_path):\n",
    "        repo_info_path = f\"{repos_data_path}/{owner}_{repo}/repo.json\"\n",
    "        if os.path.exists(repo_info_path):\n",
    "            with open(repo_info_path, 'r') as f:\n",
    "                repo_info = json.load(f)\n",
    "            metrics.at[index, 'stars'] = f\"{repo_info.get('stargazers_count', 0):d}\"\n",
    "            metrics.at[index, 'forks'] = f\"{repo_info.get('forks_count', 0):d}\"\n",
    "            metrics.at[index, 'watchers'] = f\"{repo_info.get('watchers', 0):d}\"\n",
    "            metrics.at[index, 'open_issues'] = f\"{repo_info.get('open_issues', 0):d}\"\n",
    "            metrics.at[index, 'network_count'] = f\"{repo_info.get('network_count', 0):d}\"\n",
    "            metrics.at[index, 'subscribers_count'] = f\"{repo_info.get('subscribers_count', 0):d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c3992cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['created_time'] = None\n",
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    repo_path = f\"{repos_data_path}/{owner}_{repo}\"\n",
    "    if os.path.exists(repo_path):\n",
    "        repo_info_path = f\"{repos_data_path}/{owner}_{repo}/repo.json\"\n",
    "        if os.path.exists(repo_info_path):\n",
    "            with open(repo_info_path, 'r') as f:\n",
    "                repo_info = json.load(f)\n",
    "                created_at = datetime.strptime(repo_info['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                today = datetime.strptime(\"2024-03-31T23:59:59Z\", '%Y-%m-%dT%H:%M:%SZ')\n",
    "            metrics.at[index, 'created_time'] = f\"{(today-created_at).total_seconds()/(3600*24):.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d2d20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(metrics_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6408ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 longitudinal(Recent 500 issues/pulls/commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9412ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['issue_closed_rate'] = None\n",
    "metrics['issue_time_to_close'] = None\n",
    "metrics['issue_time_to_response'] = None\n",
    "metrics['issue_monthly'] = None\n",
    "metrics['issue_participants'] = None\n",
    "metrics['issue_per_participants']= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fceec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['issue_commented_rate'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ac6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    \n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    \n",
    "    issues_path = f\"{repos_data_path}/{owner}_{repo}/issues.json\"\n",
    "    \n",
    "    if os.path.exists(issues_path):\n",
    "        closed_issues_count = 0\n",
    "        labeled_issues_count = 0\n",
    "        commented_issues_count = 0\n",
    "        total_comments = 0\n",
    "        total_time_to_comment = 0\n",
    "        total_time_to_close = 0\n",
    "        monthly_issues_count = defaultdict(int)\n",
    "        participants = set()\n",
    "        issues_count = 0\n",
    "        \n",
    "        with open(issues_path, 'r') as f:\n",
    "            issues = json.load(f)\n",
    "            \n",
    "        for issue in issues[:500]:\n",
    "            issues_count += 1\n",
    "#             labeled_issues_count += 1 if issue['labels'] else 0\n",
    "#             created_at = datetime.datetime.strptime(issue['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "#             monthly_issues_count[(created_at.year, created_at.month)] += 1\n",
    "\n",
    "            if issue['state'] == 'closed':\n",
    "                closed_issues_count += 1\n",
    "#                 closed_at = datetime.datetime.strptime(issue['closed_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "#                 total_time_to_close += (closed_at - created_at).total_seconds()\n",
    "\n",
    "#             comments_path = f\"{repos_data_path}/{owner}_{repo}/comments/{issue['number']}.json\"\n",
    "            \n",
    "#             if os.path.exists(comments_path):\n",
    "                \n",
    "#                 with open(comments_path, 'r') as f:\n",
    "#                     comments = json.load(f)\n",
    "                    \n",
    "#                 total_comments += len(comments)\n",
    "#                 first_comment_time = datetime.datetime.strptime(comments[0]['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "#                 time_to_comment = (first_comment_time - created_at).total_seconds()\n",
    "#                 total_time_to_comment += time_to_comment\n",
    "#                 commented_issues_count += 1\n",
    "                \n",
    "#                 for comment in comments:\n",
    "#                     participant = comment['user']['login']\n",
    "#                     participants.add(participant)\n",
    "        \n",
    "    metrics.at[index, 'issue_closed_rate'] = f\"{(closed_issues_count / issues_count):.2f}\" if issues_count > 0 else \"N/A\"\n",
    "#     metrics.at[index, 'issue_time_to_close'] = f\"{(total_time_to_close / closed_issues_count / (24 * 3600)):.1f}\" if closed_issues_count > 0 else \"N/A\"\n",
    "#     metrics.at[index, 'issue_time_to_response'] = f\"{(total_time_to_comment / commented_issues_count / (24 * 3600)):.1f}\" if commented_issues_count > 0 else \"N/A\"\n",
    "#     metrics.at[index, 'issue_monthly'] = f\"{(sum(monthly_issues_count.values()) / len(monthly_issues_count)):.1f}\" if len(monthly_issues_count) > 0 else \"N/A\"\n",
    "#     metrics.at[index, 'issue_participants'] = f\"{len(participants):d}\"\n",
    "#     metrics.at[index, 'issue_per_participants'] = f\"{(len(participants) / issues_count):.1f}\" if issues_count > 0 else \"N/A\"\n",
    "#     metrics.at[index, 'issue_commented_rate'] = f\"{(commented_issues_count / issues_count):.2f}\" if issues_count > 0 else \"N/A\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7be2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['labeled_issues'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c46e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    \n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    \n",
    "    issues_path = f\"{repos_data_path}/{owner}_{repo}/issues.json\"\n",
    "    \n",
    "    if os.path.exists(issues_path):\n",
    "        labeled_issues_count = 0\n",
    "        \n",
    "        with open(issues_path, 'r') as f:\n",
    "            issues = json.load(f)\n",
    "            \n",
    "        for issue in issues[:500]:\n",
    "            labeled_issues_count += 1 if issue['labels'] else 0\n",
    "        \n",
    "    metrics.at[index, 'labeled_issues'] = f\"{labeled_issues_count:d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5746900",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['pulls_closed_rate'] = None\n",
    "metrics['pulls_merged_rate'] = None\n",
    "metrics['pulls_time_to_close'] = None\n",
    "metrics['pulls_time_to_response'] = None\n",
    "metrics['pulls_monthly'] = None\n",
    "metrics['pulls_participants'] = None\n",
    "metrics['pulls_per_participants'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fa677ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    \n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    \n",
    "    pulls_path = f\"{repos_data_path}/{owner}_{repo}/pulls.json\"\n",
    "    \n",
    "    if os.path.exists(pulls_path):\n",
    "        pulls_count = 0\n",
    "        closed_pulls_count = 0\n",
    "        merged_pulls_count = 0\n",
    "        commented_pulls_count = 0\n",
    "        total_comments = 0\n",
    "        total_time_to_comment = 0\n",
    "        total_time_to_close = 0\n",
    "        monthly_pulls_count = defaultdict(int)\n",
    "        participants = set()\n",
    "        \n",
    "        with open(pulls_path, 'r') as f:\n",
    "            pulls = json.load(f)\n",
    "            \n",
    "        if pulls is None:\n",
    "            continue\n",
    "            \n",
    "        for pull in pulls[:500]:\n",
    "            \n",
    "            pulls_count += 1\n",
    "            \n",
    "            if pull['merged_at']:\n",
    "                merged_pulls_count += 1\n",
    "                \n",
    "            created_at = datetime.datetime.strptime(pull['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "            monthly_pulls_count[(created_at.year, created_at.month)] += 1\n",
    "\n",
    "            if pull['state'] == 'closed':\n",
    "                closed_pulls_count += 1\n",
    "                closed_at = datetime.datetime.strptime(pull['closed_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                total_time_to_close += (closed_at - created_at).total_seconds()\n",
    "\n",
    "            comments_path = f\"{repos_data_path}/{owner}_{repo}/comments/{pull['number']}.json\"\n",
    "            \n",
    "            if os.path.exists(comments_path):\n",
    "                \n",
    "                with open(comments_path, 'r') as f:\n",
    "                    comments = json.load(f)\n",
    "                    \n",
    "                total_comments += len(comments)\n",
    "                first_comment_time = datetime.datetime.strptime(comments[0]['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                time_to_comment = (first_comment_time - created_at).total_seconds()\n",
    "                total_time_to_comment += time_to_comment\n",
    "                commented_pulls_count += 1\n",
    "                \n",
    "                for comment in comments:\n",
    "                    participant = comment['user']['login']\n",
    "                    participants.add(participant)\n",
    "        \n",
    "    metrics.at[index, 'pulls_closed_rate'] = f\"{(closed_pulls_count / pulls_count):.1f}\" if pulls_count > 0 else \"N/A\"  \n",
    "    metrics.at[index, 'pulls_merged_rate'] = f\"{(merged_pulls_count / closed_pulls_count):.1f}\" if closed_pulls_count > 0 else \"N/A\"\n",
    "    metrics.at[index, 'pulls_time_to_close'] = f\"{(total_time_to_close / closed_pulls_count / (24 * 3600)):.1f}\" if closed_pulls_count > 0 else \"N/A\"\n",
    "    metrics.at[index, 'pulls_time_to_response'] = f\"{(total_time_to_comment / commented_pulls_count / (24 * 3600)):.1f}\" if commented_pulls_count > 0 else \"N/A\"\n",
    "    metrics.at[index, 'pulls_monthly'] = f\"{(sum(monthly_pulls_count.values()) / len(monthly_pulls_count)):.1f}\" if len(monthly_pulls_count) > 0 else \"N/A\"\n",
    "    metrics.at[index, 'pulls_participants'] = f\"{len(participants):d}\"\n",
    "    metrics.at[index, 'pulls_per_participants'] = f\"{(len(participants) / pulls_count):.1f}\" if pulls_count > 0 else \"N/A\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d6ec7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['issues_average_comments'] = None\n",
    "metrics['pulls_average_comments'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd00934",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['issue_most_recent_time'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e671018",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    \n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    \n",
    "    issues_path = f\"{repos_data_path}/{owner}_{repo}/issues.json\"\n",
    "    \n",
    "    if os.path.exists(issues_path):\n",
    "        total_comments = 0\n",
    "        \n",
    "        with open(issues_path, 'r') as f:\n",
    "            issues = json.load(f)\n",
    "        metrics.at[index, 'issue_most_recent_time'] = f\"{issues[0]['created_at']}\" if issues else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf46edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    \n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    \n",
    "    pulls_path = f\"{repos_data_path}/{owner}_{repo}/pulls2.json\"\n",
    "    \n",
    "    if os.path.exists(pulls_path):\n",
    "        total_comments = 0\n",
    "        \n",
    "        with open(pulls_path, 'r') as f:\n",
    "            pulls = json.load(f)\n",
    "            \n",
    "        for pull in pulls[:500]:\n",
    "            total_comments += pull['comments']\n",
    "        \n",
    "    metrics.at[index, 'pulls_average_comments'] = f\"{(total_comments / len(pulls)):.1f}\" if pulls else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff585d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['code_review_score'] = None\n",
    "metrics['maintained_score'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6b70e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    scorecard_path = f\"{repos_data_path}/{owner}_{repo}/scorecard.json\"\n",
    "    if os.path.exists(scorecard_path):\n",
    "        with open(scorecard_path, 'r') as f:\n",
    "            scorecard = json.load(f)\n",
    "    if scorecard and scorecard['checks']:\n",
    "        for check in scorecard['checks']:\n",
    "            if check['name'] == \"Code-Review\":\n",
    "                metrics.at[index, 'code_review_score'] = f\"{check['score']}\"\n",
    "            if check['name'] == \"Maintained\":\n",
    "                metrics.at[index, 'maintained_score'] = f\"{check['score']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c48d6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['vulnerabilities']= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a601352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    scorecard_path = f\"{repos_data_path}/{owner}_{repo}/scorecard.json\"\n",
    "    if os.path.exists(scorecard_path):\n",
    "        with open(scorecard_path, 'r') as f:\n",
    "            scorecard = json.load(f)\n",
    "    if scorecard and scorecard['checks']:\n",
    "        for check in scorecard['checks']:\n",
    "            if check['name'] == \"Vulnerabilities\":\n",
    "                metrics.at[index, 'vulnerabilities'] = f\"{check['reason'].split()[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3296b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['dependent_repositories'] = None\n",
    "metrics['dependent_packages'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7da589af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    dependents_path = f\"{repos_data_path}/{owner}_{repo}/dependents.json\"\n",
    "    if os.path.exists(dependents_path):\n",
    "        with open(dependents_path, 'r') as f:\n",
    "            dependents = json.load(f)\n",
    "        metrics.at[index, 'dependent_repositories'] = f\"{dependents.get('repositories', '0')}\"\n",
    "        metrics.at[index, 'dependent_packages'] = f\"{dependents.get('packages', 0)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39934c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['commits_with_vertification_rate'] = None\n",
    "metrics['commits_avg_msg_length'] = None\n",
    "metrics['commits_author_count'] = None\n",
    "metrics['commits_committer_count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18dceb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    commits_path = f\"{repos_data_path}/{owner}_{repo}/commits.json\"\n",
    "    if os.path.exists(commits_path):\n",
    "        commits_with_vertification_count = 0\n",
    "        commits_count = 0\n",
    "        commits_msg_length = 0\n",
    "        authors = set()\n",
    "        committers = set()\n",
    "        with open(commits_path, 'r') as f:\n",
    "            commits = json.load(f)\n",
    "        if commits is None:\n",
    "            continue\n",
    "        for commit in commits:\n",
    "            commits_count += 1\n",
    "            if commit['author']:\n",
    "                authors.add(commit['author']['login'])\n",
    "            if commit['committer']:\n",
    "                committers.add(commit['committer']['login'])\n",
    "            commits_msg_length += len(commit['commit']['message'])\n",
    "            if commit['commit']['verification']['verified'] is True:\n",
    "                commits_with_vertification_count += 1\n",
    "        metrics.at[index, 'commits_with_vertification_rate'] = f\"{(commits_with_vertification_count / commits_count):.1f}\" if commits_count > 0 else \"N/A\"  \n",
    "        metrics.at[index, 'commits_avg_msg_length'] = f\"{(commits_msg_length / commits_count):.1f}\" if commits_count > 0 else \"N/A\"  \n",
    "        metrics.at[index, 'commits_author_count'] = f\"{len(authors):d}\"\n",
    "        metrics.at[index, 'commits_committer_count'] = f\"{len(committers):d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fc12ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['readme_headers_num'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5855f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    readme_path = f\"{repos_data_path}/{owner}_{repo}/readme.md\"\n",
    "    if os.path.exists(readme_path):\n",
    "        heading_levels = {\n",
    "            'h1': re.compile(r'^(#\\s.*)', re.MULTILINE),\n",
    "            'h2': re.compile(r'^(##\\s.*)', re.MULTILINE),\n",
    "            'h3': re.compile(r'^(###\\s.*)', re.MULTILINE)\n",
    "        }\n",
    "        counts = 0\n",
    "        with open(readme_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                for level, regex in heading_levels.items():\n",
    "                    matches = regex.findall(line)\n",
    "                    counts += len(matches)\n",
    "        metrics.at[index, 'readme_headers_num'] = counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c56559",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['comments_avg_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e160df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    \n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    \n",
    "    issues_path = f\"{repos_data_path}/{owner}_{repo}/issues.json\"\n",
    "    \n",
    "    if os.path.exists(issues_path):\n",
    "        comments_count = 0\n",
    "        comments_length = 0\n",
    "        \n",
    "        with open(issues_path, 'r') as f:\n",
    "            issues = json.load(f)\n",
    "            \n",
    "        for issue in issues[:500]:\n",
    "            comments_path = f\"{repos_data_path}/{owner}_{repo}/comments/{issue['number']}.json\"\n",
    "            \n",
    "            if os.path.exists(comments_path):\n",
    "                with open(comments_path, 'r') as f:\n",
    "                    comments = json.load(f)\n",
    "                for comment in comments:\n",
    "                    comments_length += len(comment['body'])\n",
    "                    comments_count += 1\n",
    "        \n",
    "    metrics.at[index, 'comments_avg_length'] = f\"{(comments_length / comments_count):.2f}\" if comments_count > 0 else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0719b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['pulls_last_90days'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a764f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    target_date_aware = datetime(2023, 12, 1, tzinfo=pytz.utc)\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    pulls_count = 0\n",
    "    pulls_path = f\"{repos_data_path}/{owner}_{repo}/pulls.json\"\n",
    "    if os.path.exists(pulls_path):\n",
    "        with open(pulls_path, 'r') as f:\n",
    "            pulls = json.load(f)\n",
    "        if pulls is None:\n",
    "            continue\n",
    "        for pull in pulls[:500]:\n",
    "            date_str = pull['created_at']\n",
    "            date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "            date_obj_aware = date_obj.replace(tzinfo=pytz.utc)\n",
    "            if date_obj_aware > target_date_aware:\n",
    "                pulls_count += 1\n",
    "    metrics.at[index, 'pulls_last_90days'] = f\"{pulls_count:d}\" if pulls_count > 0 else \"N/A\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe699c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['commmits_last_90days'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed84f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    target_date_aware = datetime(2023, 12, 1, tzinfo=pytz.utc)\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    commits_count = 0\n",
    "    commits_path = f\"{repos_data_path}/{owner}_{repo}/commits.json\"\n",
    "    if os.path.exists(commits_path):\n",
    "        with open(commits_path, 'r') as f:\n",
    "            commits = json.load(f)\n",
    "        if commits is None:\n",
    "            continue\n",
    "        for commit in commits[:500]:\n",
    "            date_str = commit['commit']['committer']['date']\n",
    "            date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "            date_obj_aware = date_obj.replace(tzinfo=pytz.utc)\n",
    "            if date_obj_aware > target_date_aware:\n",
    "                commits_count += 1\n",
    "    metrics.at[index, 'commmits_last_90days'] = f\"{commits_count:d}\" if commits_count > 0 else \"N/A\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638ff345",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['commit_most_recent_time'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec94c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    commits_path = f\"{repos_data_path}/{owner}_{repo}/commits.json\"\n",
    "    if os.path.exists(commits_path):\n",
    "        with open(commits_path, 'r') as f:\n",
    "            commits = json.load(f)\n",
    "        metrics.at[index, 'commit_most_recent_time'] = f\"{commits[0]['commit']['author']['date']}\" if commits else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d643300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['health_percentage'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a04f34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    profile_path = f\"{repos_data_path}/{owner}_{repo}/profile.json\"\n",
    "    if os.path.exists(profile_path):\n",
    "        with open(profile_path, 'r') as f:\n",
    "            profile = json.load(f)\n",
    "        metrics.at[index, 'health_percentage'] = f\"{profile.get('health_percentage')}\" if profile else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff010d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['projects_owned_by_maintainer'] = None\n",
    "metrics['age_of_other_projects'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b047f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    maintainer_path = f\"{repos_data_path}/{owner}_{repo}/maintainer.json\"\n",
    "    today = datetime.strptime(\"2024-03-31T23:59:59Z\", '%Y-%m-%dT%H:%M:%SZ')\n",
    "    age = 0\n",
    "    if os.path.exists(maintainer_path):\n",
    "        with open(maintainer_path, 'r') as f:\n",
    "            maintainer = json.load(f)\n",
    "        for repo in maintainer:\n",
    "            if isinstance(repo, dict):\n",
    "                created_at = datetime.strptime(repo['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                age += (today - created_at).total_seconds()\n",
    "    metrics.at[index, 'projects_owned_by_maintainer'] = f\"{len(maintainer)}\" if maintainer else \"N/A\"\n",
    "    metrics.at[index, 'age_of_other_projects'] = f\"{age / len(maintainer) / (3600*24):.1f}\" if maintainer else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61d8866",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['workflow_runs_count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40204aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    workflow_path = f\"{repos_data_path}/{owner}_{repo}/workflow.json\"\n",
    "    if os.path.exists(workflow_path):\n",
    "        with open(workflow_path, 'r') as f:\n",
    "            workflow = json.load(f)\n",
    "    metrics.at[index, 'workflow_runs_count'] = f\"{workflow['total_count']}\" if workflow else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e76a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['contributors_per_code_file'] = None\n",
    "metrics['files_with_more_than_1_contributors'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c7b0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    commits_path = f\"{repos_data_path}/{owner}_{repo}/commits.json\"\n",
    "    if os.path.exists(commits_path):\n",
    "        with open(commits_path, 'r') as f:\n",
    "            commits = json.load(f)\n",
    "        if commits is None:\n",
    "            continue\n",
    "        file_contributors = {}\n",
    "        for commit in commits:\n",
    "            commit_sha = commit['sha']\n",
    "            commit_path = f\"{repos_data_path}/{owner}_{repo}/commits/{commit_sha}.json\"\n",
    "            if os.path.exists(commit_path):\n",
    "                with open(commit_path, 'r') as f:\n",
    "                    commit_data = json.load(f)\n",
    "                if commit_data.get('author'):\n",
    "                    author = commit_data['author']['login']\n",
    "                    for file in commit_data['files']:\n",
    "                        filename = file['filename']\n",
    "                        if filename not in file_contributors:\n",
    "                            file_contributors[filename] = set()\n",
    "                        file_contributors[filename].add(author)\n",
    "        total_contributors = 0\n",
    "        total_files = 0\n",
    "        files_with_more_than_1_contributors = 0\n",
    "        for contributors in file_contributors.values():\n",
    "            total_contributors += len(contributors)\n",
    "            total_files += 1\n",
    "            if len(contributors) > 1:\n",
    "                files_with_more_than_1_contributors += 1\n",
    "        num_files = len(file_contributors)\n",
    "        metrics.at[index, 'contributors_per_code_file'] = total_contributors / total_files if total_files > 0 else \"N/A\"\n",
    "#         metrics.at[index, 'files_with_more_than_1_contributors'] = f\"{files_with_more_than_1_contributors}\" if files_with_more_than_1_contributors > 0 else \"N/A\" \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3eee53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['labels'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8de0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    labels_path = f\"{repos_data_path}/{owner}_{repo}/labels.json\"\n",
    "    if os.path.exists(labels_path):\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "    metrics.at[index, 'labels'] = f\"{len(labels)}\" if labels else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c340cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['releases'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbb646bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    releases_path = f\"{repos_data_path}/{owner}_{repo}/releases.json\"\n",
    "    if os.path.exists(releases_path):\n",
    "        with open(releases_path, 'r') as f:\n",
    "            releases = json.load(f)\n",
    "    metrics.at[index, 'releases'] = f\"{len(releases)}\" if releases else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b9c9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['pull_authors_dec'] = None\n",
    "metrics['pull_authors_jan'] = None\n",
    "metrics['pull_difference'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6145150",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    dec_aware = datetime(2023, 12, 1, tzinfo=pytz.utc)\n",
    "    jan_aware = datetime(2024, 1, 1, tzinfo=pytz.utc)\n",
    "    feb_aware = datetime(2024, 2, 1, tzinfo=pytz.utc)\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    commits_count = 0\n",
    "    pulls_path = f\"{repos_data_path}/{owner}_{repo}/pulls.json\"\n",
    "    if os.path.exists(pulls_path):\n",
    "        with open(pulls_path, 'r') as f:\n",
    "            pulls = json.load(f)\n",
    "        if pulls is None:\n",
    "            continue\n",
    "        dec_authors = set()\n",
    "        jan_authors = set()\n",
    "        for pull in pulls[:500]:\n",
    "            author = pull['user']['login']\n",
    "            date_str = pull['created_at']\n",
    "            date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "            date_obj_aware = date_obj.replace(tzinfo=pytz.utc)\n",
    "            if date_obj_aware > dec_aware and date_obj_aware < jan_aware:\n",
    "                dec_authors.add(author)\n",
    "            elif date_obj_aware > jan_aware and date_obj_aware < feb_aware:\n",
    "                jan_authors.add(author)\n",
    "    metrics.at[index, 'pull_authors_dec'] = f\"{len(dec_authors):d}\" if len(dec_authors) > 0 else \"N/A\"\n",
    "    metrics.at[index, 'pull_authors_jan'] = f\"{len(jan_authors):d}\" if len(jan_authors) > 0 else \"N/A\"\n",
    "    metrics.at[index, 'pull_difference'] = f\"{len(jan_authors)-len(dec_authors):d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba328deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['pull_authors_2024'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80cd418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    jan_aware = datetime(2024, 1, 1, tzinfo=pytz.utc)\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    commits_count = 0\n",
    "    pulls_path = f\"{repos_data_path}/{owner}_{repo}/pulls.json\"\n",
    "    if os.path.exists(pulls_path):\n",
    "        with open(pulls_path, 'r') as f:\n",
    "            pulls = json.load(f)\n",
    "        if pulls is None:\n",
    "            continue\n",
    "        authors = set()\n",
    "        for pull in pulls[:500]:\n",
    "            author = pull['user']['login']\n",
    "            date_str = pull['created_at']\n",
    "            date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "            date_obj_aware = date_obj.replace(tzinfo=pytz.utc)\n",
    "            if date_obj_aware > jan_aware:\n",
    "                authors.add(author)\n",
    "    metrics.at[index, 'pull_authors_2024'] = f\"{len(authors):d}\" if len(authors) > 0 else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93598de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['Usage_Popularity'] = None\n",
    "for index, row in metrics.iterrows():\n",
    "    metrics.at[index, 'Usage_Popularity'] = (metrics.at[index, 'stars']+metrics.at[index, 'watchers']+metrics.at[index, 'forks']+metrics.at[index, 'dependent_repositories'])/4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cadb39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['headings_count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics.iterrows():\n",
    "    owner = row['owner']\n",
    "    repo = row['repo']\n",
    "    contributing_path = f\"{repos_data_path}/{owner}_{repo}/CONTRIBUTING.md\"\n",
    "    code_of_conduct_path = f\"{repos_data_path}/{owner}_{repo}/code-of-conduct.md\"\n",
    "    governance_path = f\"{repos_data_path}/{owner}_{repo}/GOVERNANCE.md\"\n",
    "    counts = 0\n",
    "    if os.path.exists(contributing_path):\n",
    "        heading_levels = {\n",
    "            'h1': re.compile(r'^(#\\s.*)', re.MULTILINE),\n",
    "            'h2': re.compile(r'^(##\\s.*)', re.MULTILINE),\n",
    "            'h3': re.compile(r'^(###\\s.*)', re.MULTILINE)\n",
    "        }\n",
    "        with open(contributing_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                for level, regex in heading_levels.items():\n",
    "                    matches = regex.findall(line)\n",
    "                    counts += len(matches)\n",
    "    if os.path.exists(code_of_conduct_path):\n",
    "        heading_levels = {\n",
    "            'h1': re.compile(r'^(#\\s.*)', re.MULTILINE),\n",
    "            'h2': re.compile(r'^(##\\s.*)', re.MULTILINE),\n",
    "            'h3': re.compile(r'^(###\\s.*)', re.MULTILINE)\n",
    "        }\n",
    "        with open(code_of_conduct_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                for level, regex in heading_levels.items():\n",
    "                    matches = regex.findall(line)\n",
    "                    counts += len(matches)\n",
    "    if os.path.exists(governance_path):\n",
    "        heading_levels = {\n",
    "            'h1': re.compile(r'^(#\\s.*)', re.MULTILINE),\n",
    "            'h2': re.compile(r'^(##\\s.*)', re.MULTILINE),\n",
    "            'h3': re.compile(r'^(###\\s.*)', re.MULTILINE)\n",
    "        }\n",
    "        with open(governance_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                for level, regex in heading_levels.items():\n",
    "                    matches = regex.findall(line)\n",
    "                    counts += len(matches)\n",
    "        metrics.at[index, 'readme_headers_num'] = counts "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
