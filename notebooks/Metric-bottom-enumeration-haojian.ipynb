{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127dcdd6",
   "metadata": {},
   "source": [
    "#### The goal of this notebook is to enumerate all the repository metrics that are potentially useful for trustworthy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb7c786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "795c5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final metric criterias:\n",
    "### 1. We do not include the metrics the are already easy to access on github pages.\n",
    "### 2. We do not include the metrics that requires significant resources to build. The initial set of simple metrics can help a long way.\n",
    "### 3. We include metrics that even are not available. we will remove them at the end. \n",
    "### 4. We focus on quantifiable metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe54b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Github\n",
    "\n",
    "# 1. Star\n",
    "# 2. Folk\n",
    "# 3. Watching\n",
    "# 4. Commits\n",
    "# 5. Issue\n",
    "# 6. PL (Programming Language used by the OSS)\n",
    "# 7. Pull Request\n",
    "# 8. Actions (I assume that unit tests is a part of Action. Or I may)\n",
    "# 9. Docs (Readme.md, Governance.md, Open source license.md, Security.md)\n",
    "# 10. Contributor\n",
    "# 11. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "285e6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw metric categories\n",
    "\n",
    "# We start with basic repo features first.\n",
    "basic_metrics = [\"stars\", \"folks\", \"subscribers\", \"commits\", \"issues\", \"PL\", \"pulls\", \"actions\", \"docs\", \"contributors\", \"code\"]\n",
    "\n",
    "# These features are mostly about cosmetic information, e.g., whether the commit messages are well formatted and detailed, whether the code has enough comments. \n",
    "cosmetic_metrics = [\"commits\", \"issues\", \"pulls\", \"docs\", \"code\"] # code here mean in-code comments.\n",
    "\n",
    "# this metrics involve code.\n",
    "code_metrics = [\"commits\", \"pulls\"]\n",
    "\n",
    "# this metrics involve timestamps. \n",
    "longitudinal_metrics = [\"commits\", \"issues\", \"pulls\", \"actions\"]\n",
    "\n",
    "# this metrics involve contributors.\n",
    "contributor_metrics = [\"stars\", \"folks\", \"subscribers\", \"commits\", \"issues\", \"pulls\"]\n",
    "\n",
    "# special metrics. we will need to enumerate more. we possiblely need to put all the external metrics here.\n",
    "special_metrics = [\"languages\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d77cbb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define enumeration metrics. The first letter indicate the data types. b means binary, n means numeric.\n",
    "cosmetic_combos = [\"b_msg_format\", \"n_msg_length\"]\n",
    "\n",
    "code_combos = [\"n_total_code_length\", \"n_avg_code_length\", \"n_avg_num_of_involved_files\"]\n",
    "\n",
    "longitudinal_combos = [\"n_earliest_time\", \"n_most_recent_time\", \"n_totalnum\", \"n_percentage_succeed\"] # n_percentage_succeed refers to whether a issue is closed, whether a pull request is merged, etc. \n",
    "\n",
    "# note we define contributors broadly here. A participant that involves in an issue discussion is also a contributor.\n",
    "contributor_combos = [\"n_total_contributor\", \"n_avg_contributor\"]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff038c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['commits_b_msg_format', 'commits_n_msg_length', 'issues_b_msg_format', 'issues_n_msg_length', 'pulls_b_msg_format', 'pulls_n_msg_length', 'docs_b_msg_format', 'docs_n_msg_length', 'code_b_msg_format', 'code_n_msg_length', 'commits_n_total_code_length', 'commits_n_avg_code_length', 'commits_n_avg_num_of_involved_files', 'pulls_n_total_code_length', 'pulls_n_avg_code_length', 'pulls_n_avg_num_of_involved_files', 'commits_n_earliest_time', 'commits_n_most_recent_time', 'commits_n_totalnum', 'issues_n_earliest_time', 'issues_n_most_recent_time', 'issues_n_totalnum', 'pulls_n_earliest_time', 'pulls_n_most_recent_time', 'pulls_n_totalnum', 'actions_n_earliest_time', 'actions_n_most_recent_time', 'actions_n_totalnum', 'stars_n_total_contributor', 'stars_n_avg_contributor', 'folks_n_total_contributor', 'folks_n_avg_contributor', 'subscribers_n_total_contributor', 'subscribers_n_avg_contributor', 'commits_n_total_contributor', 'commits_n_avg_contributor', 'issues_n_total_contributor', 'issues_n_avg_contributor', 'pulls_n_total_contributor', 'pulls_n_avg_contributor']\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "all_metrics = []\n",
    "for metric1 in cosmetic_metrics: \n",
    "    for metric2 in cosmetic_combos:\n",
    "        all_metrics.append(metric1 + \"_\" + metric2)\n",
    "        \n",
    "        \n",
    "for metric1 in code_metrics: \n",
    "    for metric2 in code_combos:\n",
    "        all_metrics.append(metric1 + \"_\" + metric2)\n",
    "        \n",
    "        \n",
    "for metric1 in longitudinal_metrics: \n",
    "    for metric2 in longitudinal_combos:\n",
    "        all_metrics.append(metric1 + \"_\" + metric2)        \n",
    "        \n",
    "\n",
    "for metric1 in contributor_metrics: \n",
    "    for metric2 in contributor_combos:\n",
    "        all_metrics.append(metric1 + \"_\" + metric2) \n",
    "        \n",
    "\n",
    "# all_metrics.append() # TODO: Add special metrics here. \n",
    "print(all_metrics)\n",
    "print(len(all_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea696e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
